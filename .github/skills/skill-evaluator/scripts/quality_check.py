#!/usr/bin/env python3
"""ã‚¹ã‚­ãƒ«ã®é™çš„å“è³ªãƒã‚§ãƒƒã‚¯ã€‚

agentskills.io ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«åŸºã¥ã„ã¦
ã‚¹ã‚­ãƒ«ã®å“è³ªã‚’æ¤œæŸ»ã™ã‚‹ã€‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã¯åˆ¥ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å ±å‘Šã™ã‚‹ã€‚

ä½¿ã„æ–¹:
    python quality_check.py                        # .github/skills/ ä»¥ä¸‹ã‚’å…¨ãƒã‚§ãƒƒã‚¯
    python quality_check.py --skill <skill-name>   # ç‰¹å®šã‚¹ã‚­ãƒ«ã®ã¿
    python quality_check.py --path <dir>           # ä»»æ„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¹ã‚­ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
"""
from __future__ import annotations

import argparse
import io
import os
import re
import sys
import tokenize


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼è§£æ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def parse_frontmatter(content: str) -> tuple[dict, str]:
    """YAML ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã¨æœ¬æ–‡ã‚’åˆ†é›¢ã—ã¦ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ã€‚

    Returns:
        (frontmatter_dict, body_text)
        ãƒã‚¹ãƒˆã•ã‚ŒãŸ metadata ã‚­ãƒ¼ã¯ dict ã¨ã—ã¦è¿”ã™ã€‚
    """
    if not content.startswith("---"):
        return {}, content
    parts = content.split("---", 2)
    if len(parts) < 3:
        return {}, content
    raw = parts[1].strip()
    body = parts[2]

    fm: dict = {}
    current_parent: str | None = None
    nested: dict = {}

    for line in raw.splitlines():
        if not line.strip() or line.strip().startswith("#"):
            continue
        stripped = line.lstrip()
        indent = len(line) - len(stripped)

        if ":" not in stripped:
            continue
        key, _, value = stripped.partition(":")
        key = key.strip()
        value = value.strip().strip("\"'")

        if indent == 0:
            if nested and current_parent:
                fm[current_parent] = nested
            current_parent = key
            nested = {}
            if value:
                fm[key] = value
                current_parent = None
                nested = {}
        else:
            if value:
                nested[key] = value

    if nested and current_parent:
        fm[current_parent] = nested

    return fm, body


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å“è³ªãƒã‚§ãƒƒã‚¯ãƒ«ãƒ¼ãƒ«å®šç¾©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_RESERVED_WORDS = {"anthropic"}

_AMBIGUOUS_NAMES = {
    "helper", "utils", "tools", "documents", "data", "files",
    "misc", "common", "general", "utility", "support",
}

_FIRST_PERSON_PATTERNS = [
    r"ãŠæ‰‹ä¼ã„ã§ãã¾ã™",
    r"ãŠæ‰‹ä¼ã„ã—ã¾ã™",
    r"ã”æ”¯æ´ã—ã¾ã™",
    r"\bI can\b",
    r"\bYou can use this to\b",
    r"\bThis helps you\b",
]

_TRIGGER_PATTERNS = [
    r"å ´åˆ",
    r"ã¨ã",
    r"[Ww]hen",
    r"ç™ºå‹•",
    r"ãªã©ã§",
    r"Use when",
    r"ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§",
    r"ã§ä½¿ç”¨ã™ã‚‹",
]

_NETWORK_PATTERNS = [
    r"\brequests\.(get|post|put|delete|patch|head|session)\b",
    r"\burllib\.request\b",
    r"\burllib\.urlopen\b",
    r"\bhttp\.client\b",
    r"\bhttpx\.",
    r"\baiohttp\.",
    r"\bfetch\s*\(",
    r"\bcurl\b",
    r"\bwget\b",
]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ãƒ«ãƒ¼ãƒ«å®šç¾©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸèªè¨¼æƒ…å ±ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
_CREDENTIAL_PATTERNS = [
    (r'(?i)(api[_-]?key|apikey)\s*[=:]\s*["\']?[A-Za-z0-9_\-]{16,}', "API ã‚­ãƒ¼"),
    (r'(?i)(secret|password|passwd|pwd)\s*[=:]\s*["\'][^"\']{8,}', "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰/ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆ"),
    (r'(?i)(token)\s*[=:]\s*["\']?[A-Za-z0-9_\-\.]{20,}', "ãƒˆãƒ¼ã‚¯ãƒ³"),
    (r'(?i)Authorization\s*[=:]\s*["\']?Bearer\s+[A-Za-z0-9_\-\.]+', "Bearer ãƒˆãƒ¼ã‚¯ãƒ³"),
    (r'(?i)(access[_-]?key|private[_-]?key)\s*[=:]\s*["\']?[A-Za-z0-9/+=]{20,}', "ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼"),
]

# æ•µå¯¾çš„æŒ‡ç¤ºãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå®‰å…¨ãƒ«ãƒ¼ãƒ«ã®è¿‚å›ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®éš è”½ãƒ»ãƒ‡ãƒ¼ã‚¿æµå‡ºï¼‰
_ADVERSARIAL_PATTERNS = [
    (r'(?i)(ignore|bypass|override|disregard)\s+(safety|security|rule|guideline|restriction|filter)', "å®‰å…¨ãƒ«ãƒ¼ãƒ«ã®è¿‚å›æŒ‡ç¤º"),
    (r'(?i)hide\s+(this|from\s+(the\s+)?user|action)', "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®éš è”½æŒ‡ç¤º"),
    (r'(?i)do\s+not\s+(tell|show|reveal|disclose|inform)', "æƒ…å ±é–‹ç¤ºæ‹’å¦æŒ‡ç¤º"),
    (r'(?i)without\s+(the\s+)?user.{0,10}knowledge', "ãƒ¦ãƒ¼ã‚¶ãƒ¼éèªçŸ¥æ“ä½œ"),
    (r'(?i)exfiltrat', "ãƒ‡ãƒ¼ã‚¿æµå‡ºæŒ‡ç¤º"),
    (r'å®‰å…¨.{0,10}(ç„¡è¦–|è¿‚å›|ãƒã‚¤ãƒ‘ã‚¹)', "å®‰å…¨ãƒ«ãƒ¼ãƒ«ç„¡è¦–æŒ‡ç¤ºï¼ˆæ—¥æœ¬èªï¼‰"),
    (r'ãƒ¦ãƒ¼ã‚¶ãƒ¼.{0,15}(éš |çŸ¥ã‚‰ã›|éè¡¨ç¤º)', "ãƒ¦ãƒ¼ã‚¶ãƒ¼éš è”½æŒ‡ç¤ºï¼ˆæ—¥æœ¬èªï¼‰"),
]

# MCP ã‚µãƒ¼ãƒãƒ¼å‚ç…§ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆServerName:tool_name å½¢å¼ï¼‰
_MCP_PATTERN = r'\b([A-Z][a-zA-Z0-9]+):([a-z][a-z0-9_]+)\b'

# å¤–éƒ¨ URL ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆlocalhost é™¤å¤–ï¼‰
_EXTERNAL_URL_PATTERN = r'https?://(?!localhost\b|127\.0\.0\.1\b)[^\s\)\]"\'`]+'

# ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
_PATH_TRAVERSAL_PATTERN = r'\.\.[/\\]'

# åºƒç¯„ãª glob ãƒ‘ã‚¿ãƒ¼ãƒ³
_BROAD_GLOB_PATTERN = r'(\*\*/\*|(?<!\w)\*\*$|\*\*\s|/\*[^.])'

# ãƒ‡ãƒ¼ã‚¿æµå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ©Ÿå¯†èª­ã¿å–ã‚Šå¾Œã«å¤–éƒ¨é€ä¿¡ï¼‰
_EXFIL_READ_PATTERNS = [
    r'\b(open|read|cat|get_contents?)\b.{0,100}\b(password|secret|key|token|credential)',
]
_EXFIL_SEND_PATTERNS = [
    r'\b(requests\.(post|put)|urllib|curl|wget|send|upload|transmit)\b',
]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å“è³ªãƒã‚§ãƒƒã‚¯é–¢æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def check_name(name: str) -> list[dict]:
    issues = []
    for word in _RESERVED_WORDS:
        if word in name.lower():
            issues.append({
                "severity": "error",
                "code": "NAME_RESERVED_WORD",
                "message": f"name ã«äºˆç´„èª '{word}' ãŒå«ã¾ã‚Œã¦ã„ã¾ã™",
            })
    name_parts = set(name.lower().replace("-", " ").split())
    if name.lower() in _AMBIGUOUS_NAMES or name_parts & _AMBIGUOUS_NAMES == name_parts:
        issues.append({
            "severity": "warning",
            "code": "NAME_AMBIGUOUS",
            "message": f"name '{name}' ãŒæ›–æ˜§ã¾ãŸã¯æ±ç”¨çš„ã™ãã¾ã™ã€‚ã‚ˆã‚Šå…·ä½“çš„ãªåå‰ã‚’æ¨å¥¨ã—ã¾ã™",
        })
    return issues


def check_description(desc: str) -> list[dict]:
    issues = []
    if re.search(r"<[a-zA-Z/]", desc):
        issues.append({
            "severity": "error",
            "code": "DESC_XML_TAG",
            "message": "description ã« XML ã‚¿ã‚°ãŒå«ã¾ã‚Œã¦ã„ã¾ã™",
        })
    for pattern in _FIRST_PERSON_PATTERNS:
        if re.search(pattern, desc):
            issues.append({
                "severity": "warning",
                "code": "DESC_FIRST_PERSON",
                "message": "description ãŒä¸€äººç§°ã§æ›¸ã‹ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä¸‰äººç§°ï¼ˆã€Œã€œã™ã‚‹ã€ã€Œã€œã‚’è¡Œã†ã€ï¼‰ã§è¨˜è¿°ã—ã¦ãã ã•ã„",
            })
            break
    has_trigger = any(re.search(p, desc) for p in _TRIGGER_PATTERNS)
    if not has_trigger:
        issues.append({
            "severity": "warning",
            "code": "DESC_NO_TRIGGER",
            "message": "description ã«ã‚¹ã‚­ãƒ«ç™ºå‹•ã®ãƒˆãƒªã‚¬ãƒ¼æ¡ä»¶ï¼ˆã€Œã€œã®å ´åˆã€ã€Œã€œã¨ãã€ã€Œã€œãªã©ã§ç™ºå‹•ã€ç­‰ï¼‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“",
        })
    return issues


def check_metadata_version(fm: dict) -> list[dict]:
    issues = []
    metadata = fm.get("metadata")
    if not isinstance(metadata, dict):
        issues.append({
            "severity": "warning",
            "code": "META_NO_VERSION",
            "message": 'metadata.version ãŒæœªè¨­å®šã§ã™ã€‚ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã« metadata: / version: "1.0" ã‚’è¿½åŠ ã—ã¦ãã ã•ã„',
        })
    elif "version" not in metadata:
        issues.append({
            "severity": "warning",
            "code": "META_NO_VERSION",
            "message": "metadata.version ãŒæœªè¨­å®šã§ã™",
        })
    return issues


def check_body(body: str, skill_dir: str) -> list[dict]:
    issues = []
    lines = body.splitlines()
    if len(lines) > 500:
        issues.append({
            "severity": "warning",
            "code": "BODY_TOO_LONG",
            "message": f"SKILL.md æœ¬æ–‡ãŒ {len(lines)} è¡Œã‚ã‚Šã¾ã™ï¼ˆæ¨å¥¨: 500 è¡Œä»¥ä¸‹ï¼‰ã€‚references/ ã¸ã®åˆ†å‰²ã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
        })
    if re.search(r'(?:scripts|references|assets)\\', body):
        issues.append({
            "severity": "warning",
            "code": "PATH_BACKSLASH",
            "message": "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã«ãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ãŒä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ï¼ˆ/ï¼‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
        })
    ref_links = re.findall(r'\[.*?\]\(([\w./\-]+\.md)\)', body)
    checked_refs: set[str] = set()
    for ref in ref_links:
        if ref in checked_refs:
            continue
        checked_refs.add(ref)
        ref_path = os.path.join(skill_dir, ref)
        if not os.path.isfile(ref_path):
            continue
        with open(ref_path, encoding="utf-8", errors="replace") as f:
            ref_content = f.read()
        ref_lines = ref_content.splitlines()
        if len(ref_lines) >= 100:
            has_toc = any(
                re.search(r'^#{1,3}\s*(ç›®æ¬¡|Contents?|Table of Contents)', line)
                for line in ref_lines[:20]
            )
            if not has_toc:
                issues.append({
                    "severity": "warning",
                    "code": "REF_NO_TOC",
                    "message": f"{ref} ã¯ {len(ref_lines)} è¡Œã‚ã‚Šã¾ã™ãŒå…ˆé ­ã«ç›®æ¬¡ï¼ˆ## ç›®æ¬¡ï¼‰ãŒã‚ã‚Šã¾ã›ã‚“",
                })
        nested_refs = re.findall(r'\[.*?\]\(([\w./\-]+\.md)\)', ref_content)
        if nested_refs:
            issues.append({
                "severity": "warning",
                "code": "REF_NESTED",
                "message": f"{ref} ãŒã•ã‚‰ã«ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦ã„ã¾ã™ï¼ˆæ¨å¥¨: SKILL.md ã‹ã‚‰ 1 éšå±¤ã®ã¿ï¼‰",
            })
    return issues


def check_scripts(skill_dir: str) -> list[dict]:
    issues = []
    scripts_dir = os.path.join(skill_dir, "scripts")
    if not os.path.isdir(scripts_dir):
        return issues

    def strip_python_literals(content: str) -> str:
        """Python ã®æ–‡å­—åˆ—/ã‚³ãƒ¡ãƒ³ãƒˆã‚’é™¤å»ã—ã¦èª¤æ¤œçŸ¥ã‚’æŠ‘ãˆã‚‹ã€‚"""
        tokens: list[tuple[int, str]] = []
        try:
            for token in tokenize.generate_tokens(io.StringIO(content).readline):
                if token.type in (tokenize.STRING, tokenize.COMMENT):
                    continue
                tokens.append((token.type, token.string))
            return tokenize.untokenize(tokens)
        except (tokenize.TokenError, IndentationError):
            return content

    for fname in sorted(os.listdir(scripts_dir)):
        if not fname.endswith((".py", ".sh")):
            continue
        fpath = os.path.join(scripts_dir, fname)
        with open(fpath, encoding="utf-8", errors="replace") as f:
            content = f.read()
        if fname.endswith(".py"):
            content = strip_python_literals(content)
        for pattern in _NETWORK_PATTERNS:
            if re.search(pattern, content):
                issues.append({
                    "severity": "warning",
                    "code": "SCRIPT_NETWORK",
                    "message": f"scripts/{fname} ã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å‘¼ã³å‡ºã—ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆæ„å›³çš„ãªå ´åˆã¯ç„¡è¦–ã—ã¦ãã ã•ã„ï¼‰",
                })
                break
    return issues


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯é–¢æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _collect_all_text(skill_dir: str) -> dict[str, str]:
    """ã‚¹ã‚­ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†ã™ã‚‹ã€‚"""
    texts: dict[str, str] = {}
    for root, _, files in os.walk(skill_dir):
        for fname in files:
            if fname.endswith((".md", ".py", ".sh", ".js", ".txt", ".yaml", ".yml", ".json")):
                fpath = os.path.join(root, fname)
                rel = os.path.relpath(fpath, skill_dir)
                try:
                    with open(fpath, encoding="utf-8", errors="replace") as f:
                        texts[rel] = f.read()
                except OSError:
                    pass
    return texts


def security_check(skill_dir: str) -> list[dict]:
    """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã‚’æ¤œå‡ºã—ã¦è¿”ã™ã€‚è©•ä¾¡åŸºæº–ã«ã¯å½±éŸ¿ã—ãªã„ã€‚

    Returns:
        list of {"level": "HIGH"|"MEDIUM", "code": str, "message": str}
    """
    risks: list[dict] = []
    texts = _collect_all_text(skill_dir)

    skill_md_content = texts.get("SKILL.md", "")
    _, skill_body = parse_frontmatter(skill_md_content)

    # â”€â”€ HIGH: ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸèªè¨¼æƒ…å ± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for rel, content in texts.items():
        for pattern, cred_type in _CREDENTIAL_PATTERNS:
            if re.search(pattern, content):
                risks.append({
                    "level": "HIGH",
                    "code": "SEC_HARDCODED_CREDENTIAL",
                    "message": f"{rel} ã«ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸ {cred_type} ãŒç–‘ã‚ã‚Œã¾ã™ã€‚ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
                })
                break  # 1ãƒ•ã‚¡ã‚¤ãƒ«1ä»¶

    # â”€â”€ HIGH: æ•µå¯¾çš„æŒ‡ç¤ºï¼ˆSKILL.md ã¨å‚ç…§ .md ã®ã¿å¯¾è±¡ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    md_texts = {k: v for k, v in texts.items() if k.endswith(".md")}
    for rel, content in md_texts.items():
        for pattern, label in _ADVERSARIAL_PATTERNS:
            if re.search(pattern, content):
                risks.append({
                    "level": "HIGH",
                    "code": "SEC_ADVERSARIAL_INSTRUCTION",
                    "message": f"{rel} ã« {label} ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                })
                break

    # â”€â”€ HIGH: å¤–éƒ¨ URLï¼ˆSKILL.md ã¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ã¿å¯¾è±¡ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å‚ç…§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆreferences/ ç­‰ï¼‰å†…ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”¨ URL ã¯å¯¾è±¡å¤–
    url_check_texts = {
        k: v for k, v in texts.items()
        if k == "SKILL.md" or k.startswith("scripts/") or k.startswith("scripts" + os.sep)
    }
    seen_url_domains: set[tuple[str, str]] = set()
    for rel, content in url_check_texts.items():
        urls = re.findall(_EXTERNAL_URL_PATTERN, content)
        for url in urls:
            domain_m = re.match(r'https?://([^/\s]+)', url)
            key = (rel, domain_m.group(1) if domain_m else url)
            if key in seen_url_domains:
                continue
            seen_url_domains.add(key)
            risks.append({
                "level": "HIGH",
                "code": "SEC_EXTERNAL_URL",
                "message": f"{rel} ã«å¤–éƒ¨ URL ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {url[:80]}",
            })

    # â”€â”€ HIGH: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    script_texts = {k: v for k, v in texts.items()
                    if k.startswith("scripts" + os.sep) or k.startswith("scripts/")}
    for rel, content in script_texts.items():
        for pattern in _NETWORK_PATTERNS:
            if re.search(pattern, content):
                risks.append({
                    "level": "HIGH",
                    "code": "SEC_SCRIPT_NETWORK",
                    "message": f"{rel} ã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å‘¼ã³å‡ºã—ãŒã‚ã‚Šã¾ã™ï¼ˆãƒ‡ãƒ¼ã‚¿æµå‡ºãƒ™ã‚¯ãƒˆãƒ«ã«ãªã‚Šãˆã¾ã™ï¼‰",
                })
                break

    # â”€â”€ HIGH: ãƒ‡ãƒ¼ã‚¿æµå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆèª­ã¿å–ã‚Šâ†’é€ä¿¡ã®çµ„ã¿åˆã‚ã›ï¼‰â”€â”€â”€â”€
    for rel, content in script_texts.items():
        has_read = any(re.search(p, content, re.IGNORECASE) for p in _EXFIL_READ_PATTERNS)
        has_send = any(re.search(p, content, re.IGNORECASE) for p in _EXFIL_SEND_PATTERNS)
        if has_read and has_send:
            risks.append({
                "level": "HIGH",
                "code": "SEC_DATA_EXFILTRATION",
                "message": f"{rel} ã§æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿å–ã‚Šã¨å¤–éƒ¨é€ä¿¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå…±å­˜ã—ã¦ã„ã¾ã™",
            })

    # â”€â”€ HIGH: MCP ã‚µãƒ¼ãƒãƒ¼å‚ç…§ï¼ˆSKILL.mdï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    mcp_refs = re.findall(_MCP_PATTERN, skill_body)
    if mcp_refs:
        refs_str = ", ".join(f"{s}:{t}" for s, t in mcp_refs[:3])
        risks.append({
            "level": "HIGH",
            "code": "SEC_MCP_REFERENCE",
            "message": f"SKILL.md ã« MCP ã‚µãƒ¼ãƒãƒ¼å‚ç…§ãŒã‚ã‚Šã¾ã™: {refs_str}ï¼ˆã‚¹ã‚­ãƒ«å¤–ã®ã‚¢ã‚¯ã‚»ã‚¹æ‹¡å¼µï¼‰",
        })

    # â”€â”€ MEDIUM: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ« â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for rel, content in texts.items():
        if re.search(_PATH_TRAVERSAL_PATTERN, content):
            risks.append({
                "level": "MEDIUM",
                "code": "SEC_PATH_TRAVERSAL",
                "message": f"{rel} ã«ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«ï¼ˆ../ï¼‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚æ„å›³ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™",
            })

    # â”€â”€ MEDIUM: åºƒç¯„ãª glob ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ã¿å¯¾è±¡ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€
    # .md ãƒ•ã‚¡ã‚¤ãƒ«ã¯ markdown ã® **å¤ªå­—** ã¨æ··åŒã™ã‚‹ãŸã‚é™¤å¤–
    non_md_texts = {k: v for k, v in texts.items() if not k.endswith(".md")}
    for rel, content in non_md_texts.items():
        if re.search(_BROAD_GLOB_PATTERN, content):
            risks.append({
                "level": "MEDIUM",
                "code": "SEC_BROAD_GLOB",
                "message": f"{rel} ã«åºƒç¯„ãª glob ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆ**/* ç­‰ï¼‰ãŒã‚ã‚Šã¾ã™ã€‚æ„å›³ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™",
            })

    # â”€â”€ MEDIUM: ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å­˜åœ¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    exec_scripts = [
        k for k in texts
        if (k.startswith("scripts/") or k.startswith("scripts" + os.sep))
        and any(k.endswith(ext) for ext in (".py", ".sh", ".js"))
    ]
    if exec_scripts:
        risks.append({
            "level": "MEDIUM",
            "code": "SEC_SCRIPT_EXISTS",
            "message": f"å®Ÿè¡Œå¯èƒ½ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒ {len(exec_scripts)} ä»¶ã‚ã‚Šã¾ã™: {', '.join(exec_scripts[:5])}ï¼ˆå®Œå…¨ãªç’°å¢ƒã‚¢ã‚¯ã‚»ã‚¹ã§å®Ÿè¡Œã•ã‚Œã¾ã™ï¼‰",
        })

    return risks


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¡ã‚¤ãƒ³è©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def check_skill(skill_dir: str) -> dict:
    """ã‚¹ã‚­ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œæŸ»ã—ã¦çµæœã‚’è¿”ã™ã€‚"""
    skill_md = os.path.join(skill_dir, "SKILL.md")
    if not os.path.isfile(skill_md):
        return {
            "name": os.path.basename(skill_dir),
            "errors": [{"severity": "error", "code": "NO_SKILL_MD", "message": "SKILL.md ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}],
            "warnings": [],
            "security_risks": [],
        }

    with open(skill_md, encoding="utf-8") as f:
        content = f.read()

    fm, body = parse_frontmatter(content)
    all_issues: list[dict] = []

    name = fm.get("name", "")
    desc = fm.get("description", "")

    if name:
        all_issues.extend(check_name(name))
    if desc:
        all_issues.extend(check_description(desc))

    all_issues.extend(check_metadata_version(fm))
    all_issues.extend(check_body(body, skill_dir))
    all_issues.extend(check_scripts(skill_dir))

    errors = [i for i in all_issues if i["severity"] == "error"]
    warnings = [i for i in all_issues if i["severity"] == "warning"]
    security_risks = security_check(skill_dir)

    return {
        "name": name or os.path.basename(skill_dir),
        "errors": errors,
        "warnings": warnings,
        "security_risks": security_risks,
    }


def find_skill_dirs(base_dir: str) -> list[str]:
    """ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä»¥ä¸‹ã®ã‚¹ã‚­ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿”ã™ã€‚"""
    if not os.path.isdir(base_dir):
        return []
    return [
        os.path.join(base_dir, entry)
        for entry in sorted(os.listdir(base_dir))
        if os.path.isdir(os.path.join(base_dir, entry))
        and os.path.isfile(os.path.join(base_dir, entry, "SKILL.md"))
    ]


def print_results(results: list[dict]) -> int:
    """å“è³ªãƒã‚§ãƒƒã‚¯çµæœã‚’è¡¨ç¤ºã—ã¦ã‚¨ãƒ©ãƒ¼ä»¶æ•°ã‚’è¿”ã™ã€‚"""
    total_errors = 0
    total_warnings = 0

    print("â”€â”€ å“è³ªãƒã‚§ãƒƒã‚¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")
    for r in results:
        errors = r["errors"]
        warnings = r["warnings"]
        total_errors += len(errors)
        total_warnings += len(warnings)

        if not errors and not warnings:
            print(f"  âœ… {r['name']}")
            continue

        status = "âŒ" if errors else "âš ï¸ "
        print(f"  {status} {r['name']}")
        for e in errors:
            print(f"      [ERROR] {e['message']}")
        for w in warnings:
            print(f"      [WARN]  {w['message']}")

    print()
    print(f"å“è³ª: {len(results)} ã‚¹ã‚­ãƒ« / ã‚¨ãƒ©ãƒ¼ {total_errors} ä»¶ / è­¦å‘Š {total_warnings} ä»¶")

    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã¯åˆ¥ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å ±å‘Šï¼ˆè©•ä¾¡åŸºæº–ã«å½±éŸ¿ã—ãªã„ï¼‰
    skills_with_risks = [r for r in results if r.get("security_risks")]
    if skills_with_risks:
        print()
        print("â”€â”€ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ï¼ˆå‚è€ƒæƒ…å ±ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")
        print("  â€» ä»¥ä¸‹ã¯ãƒªã‚¹ã‚¯ã®å ±å‘Šã§ã™ã€‚ä¿®æ­£ã™ã‚‹ã‹ã©ã†ã‹ã¯ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ãŒåˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚\n")
        total_high = 0
        total_medium = 0
        for r in skills_with_risks:
            risks = r["security_risks"]
            high = [x for x in risks if x["level"] == "HIGH"]
            medium = [x for x in risks if x["level"] == "MEDIUM"]
            total_high += len(high)
            total_medium += len(medium)
            print(f"  ğŸ”’ {r['name']}")
            for risk in high:
                print(f"      [HIGH]   {risk['message']}")
            for risk in medium:
                print(f"      [MEDIUM] {risk['message']}")
        print()
        print(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: HIGH {total_high} ä»¶ / MEDIUM {total_medium} ä»¶")

    return total_errors


def main() -> None:
    parser = argparse.ArgumentParser(description="ã‚¹ã‚­ãƒ«ã®é™çš„å“è³ªãƒã‚§ãƒƒã‚¯")
    parser.add_argument("--skill", help="ç‰¹å®šã‚¹ã‚­ãƒ«ã®ã¿ãƒã‚§ãƒƒã‚¯ï¼ˆã‚¹ã‚­ãƒ«åï¼‰")
    parser.add_argument(
        "--path",
        default=".github/skills",
        help="ã‚¹ã‚­ãƒ«ã®ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (default: .github/skills)",
    )
    args = parser.parse_args()

    print("ğŸ” ã‚¹ã‚­ãƒ«å“è³ªãƒã‚§ãƒƒã‚¯\n")

    if args.skill:
        skill_dir = os.path.join(args.path, args.skill)
        if not os.path.isdir(skill_dir):
            home = os.environ.get("USERPROFILE", os.path.expanduser("~"))
            skill_dir = os.path.join(home, ".copilot", "skills", args.skill)
            if not os.path.isdir(skill_dir):
                print(f"[ERROR] ã‚¹ã‚­ãƒ« '{args.skill}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                sys.exit(1)
        dirs = [skill_dir]
    else:
        dirs = find_skill_dirs(args.path)
        if not dirs:
            print(f"ã‚¹ã‚­ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.path}")
            sys.exit(0)

    results = [check_skill(d) for d in dirs]
    error_count = print_results(results)
    sys.exit(1 if error_count > 0 else 0)


if __name__ == "__main__":
    main()
